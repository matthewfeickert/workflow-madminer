sampling:
  process:
    process_type: interpolated-script-cmd
    script: |
      mkdir /home/data
      mkdir /home/data/samples
      python code/configurate_ml.py {n_trainsamples} {combined_file} {input_file}
      for i in `seq 0 $(({n_trainsamples}-1))`; do  tar -czvf /home/data/Samples_$i.tar.gz /home/data/Samples_$i/*; done 
      cp -R /home/data/Samples*.tar.gz {sampleworkdir}
  publisher:
    publisher_type: 'fromglob-pub'
    outputkey: sampling_file
    globexpression: 'Samples_*.tar.gz'
  environment:
    environment_type: docker-encapsulated
    image: irinahub/docker-madminer-ml
    imagetag: 'latest'

training:
  process:
    process_type: interpolated-script-cmd 
    script: |
      mkdir /home/extract
      mkdir /home/models
      tar -xvzf {trainfolder} -C /home/extract
      mv /home/extract/home/data/Samples_*  /home/extract/home/data/Samples
      python code/train.py /home/extract/home/data/Samples {input_file}
      tar -czvf /home/models/trained_model.tar.gz /home/models/*
      cp  /home/models/trained_model.tar.gz  {trainworkdir}
  publisher:
    publisher_type: interpolated-pub
    publish:
      trained_file: '{trained_file}'
  environment:
    environment_type: docker-encapsulated
    image: irinahub/docker-madminer-ml
    imagetag: 'latest'

#

#evaluating:
#  process:
#    process_type: interpolated-script-cmd
#    script: |
#this step depends in what we want to do next
#  publisher:
#    publisher_type: interpolated-pub
#    publish:
#      eval_folder: '{inputfiles}'
#  environment:
#    environment_type: docker-encapsulated
#    image: irinahub/docker-madminer-ml
#    imagetag: 'latest'

